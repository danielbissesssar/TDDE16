{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L2: Text classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text classification is the task of sorting text documents into predefined classes. The concrete problem you will be working on in this lab is the classification of texts with respect to their political affiliation. The specific texts you are going to classify are speeches held in the [Riksdag](https://www.riksdagen.se/en/), the Swedish national legislature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Before starting with this lab, here is a quick reminder about our [Rules for hand-in assignments](https://www.ida.liu.se/~TDDE16/exam.en.shtml#handins) and the [Policy on cheating and plagiarism](https://www.ida.liu.se/~TDDE16/exam.en.shtml#cheating).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The raw data for this lab comes from [The Riksdag’s Open Data](https://data.riksdagen.se/in-english/). We have tokenized the speeches and put them into two compressed [JSON](https://en.wikipedia.org/wiki/JSON) files:\n",
    "\n",
    "* `speeches-201718.json.bz2` (speeches from the 2017/2018 parliamentary session)\n",
    "* `speeches-201819.json.bz2` (ditto, from the 2018/2019 session)\n",
    "\n",
    "We start by loading these files into two separate data frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import bz2\n",
    "\n",
    "with bz2.open('speeches-201718.json.bz2') as source:\n",
    "    speeches_201718 = pd.read_json(source)\n",
    "\n",
    "with bz2.open('speeches-201819.json.bz2') as source:\n",
    "    speeches_201819 = pd.read_json(source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you inspect the two data frames, you can see that there are three labelled columns: `id` (the official speech ID), `words` (the space-separated words of the speech), and `party` (the party of the speaker, represented by its customary abbreviation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>words</th>\n",
       "      <th>party</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>H5-002-004</td>\n",
       "      <td>eders majestäter eders kungliga högheter herr ...</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>H5-003-001</td>\n",
       "      <td>aktuell debatt om situationen för ensamkommand...</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>H5-003-002</td>\n",
       "      <td>herr talman och ledamöter jag vill börja med a...</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>H5-003-003</td>\n",
       "      <td>herr talman åhörare den här debatten handlar a...</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>H5-003-004</td>\n",
       "      <td>herr talman ansvar och rättssäkerhet är två or...</td>\n",
       "      <td>SD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>H5-003-005</td>\n",
       "      <td>herr talman jag inleder med att tacka vänsterp...</td>\n",
       "      <td>MP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>H5-003-006</td>\n",
       "      <td>herr talman vi debatterar i dag situationen fö...</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>H5-003-007</td>\n",
       "      <td>herr talman runt om i landet på torg och i kla...</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>H5-003-008</td>\n",
       "      <td>aktuell debatt om situationen för ensamkommand...</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>H5-003-009</td>\n",
       "      <td>herr talman det råder ingen tvekan om att situ...</td>\n",
       "      <td>KD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                              words party\n",
       "0  H5-002-004  eders majestäter eders kungliga högheter herr ...     S\n",
       "1  H5-003-001  aktuell debatt om situationen för ensamkommand...     V\n",
       "2  H5-003-002  herr talman och ledamöter jag vill börja med a...     S\n",
       "3  H5-003-003  herr talman åhörare den här debatten handlar a...     M\n",
       "4  H5-003-004  herr talman ansvar och rättssäkerhet är två or...    SD\n",
       "5  H5-003-005  herr talman jag inleder med att tacka vänsterp...    MP\n",
       "6  H5-003-006  herr talman vi debatterar i dag situationen fö...     C\n",
       "7  H5-003-007  herr talman runt om i landet på torg och i kla...     V\n",
       "8  H5-003-008  aktuell debatt om situationen för ensamkommand...     L\n",
       "9  H5-003-009  herr talman det råder ingen tvekan om att situ...    KD"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speeches_201718.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Throughout the lab, we will be using the speeches from 2017/2018 as our training data, and the speeches from 2018/2019 as our test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data, test_data = speeches_201718, speeches_201819"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For later reference, we store the sorted list of party abbreviations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C', 'KD', 'L', 'M', 'MP', 'S', 'SD', 'V']\n"
     ]
    }
   ],
   "source": [
    "parties = sorted(training_data['party'].unique())\n",
    "print(parties)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your first task is to get to know the data better by producing a simple visualization.\n",
    "\n",
    "If you are not familiar with the Swedish political system and the parties represented in the Riksdag in particular, then we suggest that you have a look at the Wikipedia article about the [2018 Swedish general election](https://en.wikipedia.org/wiki/2018_Swedish_general_election).\n",
    "\n",
    "For the lab, we ask you to compare the two data frames with respect to the distribution of the speeches over the different parties. Write code to generate two bar plots that visualize this information, one for the 2017/2018 speeches and one for the 2018/2019 speeches. Inspect the two plots, and compare them\n",
    "\n",
    "* to each other\n",
    "* to the results of the 2014 and the 2018 general elections\n",
    "\n",
    "Summarize your observations in a short text in the cell below.\n",
    "\n",
    "**Tip:** If you need help with creating bar plots, [Bar Plot using Pandas](https://dfrieds.com/data-visualizations/bar-plot-python-pandas) provides a useful tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " In the training set 34% of values are S\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Count the speeches relative each party. Use a semi-sorted list of parties\n",
    "count_training = training_data['party'].value_counts()\n",
    "count_test = test_data['party'].value_counts()\n",
    "sorted_parties = count_training.keys()\n",
    "\n",
    "# Arrange the order to match the x-axis\n",
    "training_sorted = [count_training[party] for party in sorted_parties]\n",
    "test_sorted = [count_test[party] for party in sorted_parties]\n",
    "\n",
    "# Create plot\n",
    "x = np.arange(len(parties))\n",
    "width = 0.35\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, training_sorted, width, label='training')\n",
    "rects2 = ax.bar(x + width/2, test_sorted, width, label='test')\n",
    "\n",
    "# Add some labels\n",
    "ax.set_ylabel('Number of speeches')\n",
    "ax.set_title('Speeches per party. Training and Test data')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(sorted_parties)\n",
    "ax.legend()\n",
    "ax.bar_label(rects1, padding=2)\n",
    "ax.bar_label(rects2, padding=2)\n",
    "\n",
    "# Show the plot\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\\n In the training set %d%% of values are S\" % \n",
    "      (100 * float(count_training['S']) / count_training.sum()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that the data is unbalanced. The S class is overrepresented and this may cause problems when training the model, since the classifier could simply classify everything as S and, as such, get a fairly high score of 34% accuracy (on the training set)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are now ready to train and evaluate a classifier. More specifically, we ask you to train a [Multinomial Naive Bayes](https://scikit-learn.org/stable/modules/naive_bayes.html#multinomial-naive-bayes) classifier. You will have to\n",
    "\n",
    "1. vectorize the speeches in the training data\n",
    "2. instantiate and fit the Naive Bayes model\n",
    "3. evaluate the model on the test data\n",
    "\n",
    "The scikit-learn library provides a convenience class [Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) that allows you to solve the first two tasks with very compact code. For the evaluation you can use the function [`classification_report`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html), which will report per-class precision, recall and F1, as well as overall accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess words\n",
    "stop_words = ['och', 'det', 'att', 'i', 'en', 'jag', 'hon', 'som', 'han', 'på', 'den', 'med', 'var', 'sig', 'för', 'så', 'till', 'är', 'men', 'ett', 'om', 'hade', 'de', 'av', 'icke', 'mig', 'du', 'henne', 'då', 'sin', 'nu', 'har', 'inte', 'hans', 'honom', 'skulle', 'hennes', 'där', 'min', 'man', 'ej', 'vid', 'kunde', 'något', 'från', 'ut', 'när', 'efter', 'upp', 'vi', 'dem', 'vara', 'vad', 'över', 'än', 'dig', 'kan', 'sina', 'här', 'ha', 'mot', 'alla', 'under', 'någon', 'eller', 'allt', 'mycket', 'sedan', 'ju', 'denna', 'själv', 'detta', 'åt', 'utan', 'varit', 'hur', 'ingen', 'mitt', 'ni', 'bli', 'blev', 'oss', 'din', 'dessa', 'några', 'deras', 'blir', 'mina', 'samma', 'vilken', 'er', 'sådan', 'vår', 'blivit', 'dess', 'inom', 'mellan', 'sådant', 'varför', 'varje', 'vilka', 'ditt', 'vem', 'vilket', 'sitta', 'sådana', 'vart', 'dina', 'vars', 'vårt', 'våra', 'ert', 'era', 'vilkas']\n",
    "def preprocess(text):    \n",
    "    return [token.lower() for token in text.split() if token.isalpha() and token.lower() not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           C       0.63      0.06      0.10       671\n",
      "          KD       0.72      0.03      0.05       821\n",
      "           L       0.50      0.03      0.05       560\n",
      "           M       0.37      0.67      0.48      1644\n",
      "          MP       0.36      0.28      0.31       809\n",
      "           S       0.47      0.83      0.60      2773\n",
      "          SD       0.58      0.17      0.26      1060\n",
      "           V       0.59      0.18      0.27       950\n",
      "\n",
      "    accuracy                           0.44      9288\n",
      "   macro avg       0.53      0.28      0.27      9288\n",
      "weighted avg       0.50      0.44      0.36      9288\n",
      "\n",
      "53% of predictions are S\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "x_train = training_data['words']\n",
    "y_train = training_data['party']\n",
    "x_test = test_data['words']\n",
    "y_test = test_data['party']\n",
    "\n",
    "def train_and_print(binary=False, ngram_range=(1,1), alpha=1.0, train=[x_train, y_train]):  \n",
    "    pipe = Pipeline(\n",
    "        [('count_vect',CountVectorizer(binary=binary, ngram_range=ngram_range, tokenizer=preprocess)),\n",
    "        ('nbClassifier',MultinomialNB(alpha=alpha))\n",
    "        ]\n",
    "    )\n",
    "    pipe.fit(*train)\n",
    "    prediction_test = pipe.predict(x_test)\n",
    "    print(classification_report(y_test, prediction_test, target_names=parties))\n",
    "    return prediction_test, pipe\n",
    "\n",
    "# These global variables will be used again later.\n",
    "prediction_test, pipe = train_and_print()\n",
    "\n",
    "print('%s%% of predictions are S' % round(100 * (prediction_test == 'S').sum() / len(prediction_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Would you have expected the results that you got?\n",
    "> Yes, somewhat. For example: the recall for the 'S' class is noticebly the highest score with 83%, and this is an expected consequence due to the dataset being overrepresented by that class. When the class prediction is uncertain the model will probably fall back on the S value and, as such, it is predicted 53% of the time and thus gets most of them right. However, this behaviour do not favour the precision score, and it significantly reduces the recall score from other classes, such as 'KD' and 'L' which only has a recall of 3%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3: Baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation metrics such as accuracy should not be understood as absolute measures of performance, but should be used only to compare different classifiers. When other classifiers are not available, a simple baseline is a classifier that generates predictions by random sampling, respecting the training set&rsquo;s class distribution. This baseline is implemented by the class [DummyClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html). What is the performance of the random baseline on the test data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy for the random baseline is 30%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy_clf.fit(x_train, y_train)\n",
    "print('The accuracy for the random baseline is %d%%' % round(dummy_clf.score(x_test, y_test)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An even dumber baseline is to predict, for every document, that class which appears most often in the training data. This baseline is also called the most frequent class baseline. What is the accuracy of that baseline on the test data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From problem 1 it can be determined that the most frequent class is S\n",
      "\n",
      "In the training set 34% of all documents are of class S\n",
      "In the test set 29% of all documents are of class S\n"
     ]
    }
   ],
   "source": [
    "print('From problem 1 it can be determined that the most frequent class is S')\n",
    "print(\"\\nIn the training set %d%% of all documents are of class S\" % \n",
    "      (100 * float(count_training['S']) / count_training.sum()))\n",
    "print(\"In the test set %d%% of all documents are of class S\" % \n",
    "      (100 * float(count_test['S']) / count_test.sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4: Creating a balanced data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you saw in Problem&nbsp;1, the distribution of the speeches over the eight different parties (classes) is imbalanced. One technique used to alleviate this is **undersampling**, in which one randomly removes samples from over-represented classes until all classes are represented with the same number of samples.\n",
    "\n",
    "Implement undersampling to create a balanced subset of the training data. Rerun the evaluation from Problem&nbsp;2 on the balanced data and compare the results. Summarise your results in a short text.\n",
    "\n",
    "**Hint:** Your balanced subset should consist of 5,752 speeches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# elements in the balanced subset:  5752\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           C       0.23      0.46      0.31       671\n",
      "          KD       0.27      0.40      0.32       821\n",
      "           L       0.24      0.46      0.32       560\n",
      "           M       0.41      0.36      0.39      1644\n",
      "          MP       0.33      0.36      0.35       809\n",
      "           S       0.80      0.26      0.39      2773\n",
      "          SD       0.40      0.43      0.42      1060\n",
      "           V       0.39      0.55      0.45       950\n",
      "\n",
      "    accuracy                           0.38      9288\n",
      "   macro avg       0.39      0.41      0.37      9288\n",
      "weighted avg       0.48      0.38      0.38      9288\n",
      "\n",
      "10% of predictions are S\n"
     ]
    }
   ],
   "source": [
    "from random import shuffle\n",
    "\n",
    "undersampled_parties = []\n",
    "lowest_frequency = count_training[-1]\n",
    "for i in parties:\n",
    "    new_data = training_data[training_data.party==i]\n",
    "    np.random.shuffle(np.array(new_data))\n",
    "    undersampled_parties.append(new_data[:lowest_frequency])\n",
    "\n",
    "undersampled_training = pd.concat(undersampled_parties)\n",
    "print('# elements in the balanced subset: ', len(undersampled_training), end='\\n\\n') \n",
    "\n",
    "undersampled_train = undersampled_training['words'], undersampled_training['party']\n",
    "undersampled_prediction_test, _ = train_and_print(train=undersampled_train)\n",
    "\n",
    "print('%s%% of predictions are S' % round(100 * (undersampled_prediction_test == 'S')\n",
    "                                          .sum() / len(undersampled_prediction_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy is a bit less, but the recall is more equally distributed on the classes now. The most frequent classes, which were previously favoured by the model with good recall, now have the worst recall (but a better precision score). The occurence percentage of the predicted class 'S' went from 53% to 10%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5: Confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **confusion matrix** is a specific table that is useful when analysing the performance of a classifier. In this table, both the rows and the columns correspond to classes, and each cell $(i, j)$ states how many times a sample with gold-standard class $i$ was predicted as belonging to class $j$.\n",
    "\n",
    "In scitkit-learn, the confusion matrix of a classifier is computed by the function [`confusion_matrix`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html). If you would rather see a visual representation, you can also use [`plot_confusion_matrix`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.plot_confusion_matrix.html).\n",
    "\n",
    "Your task is to use the confusion matrix in order to find, for each given party $p$ in the Riksdag, that other party $p'$ which the classifier that you trained in Problem&nbsp;4 most often confuses with $p$ when it predicts the party of a speaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m        C  KD   L   M  MP   S  SD   V\u001b[0m\n",
      "\u001b[1m C  \u001b[0m [311  66  57  84  38   7  53  55]\n",
      "\u001b[1m KD \u001b[0m [103 326  62 132  41  24  71  62]\n",
      "\u001b[1m L  \u001b[0m [ 66  53 257  49  27   7  45  56]\n",
      "\u001b[1m M  \u001b[0m [281 215 177 595  88  45 146  97]\n",
      "\u001b[1m MP \u001b[0m [100  74  78  60 295  62  52  88]\n",
      "\u001b[1m S  \u001b[0m [271 280 233 339 330 726 229 365]\n",
      "\u001b[1m SD \u001b[0m [112 115 130  93  37  13 452 108]\n",
      "\u001b[1m V  \u001b[0m [ 89  70  67  82  28  22  70 522]\n",
      "\n",
      "\u001b[1mGold        Prediction    Value\u001b[0m\u001b[0m\n",
      "C           M             84\n",
      "KD          M             132\n",
      "L           C             66\n",
      "M           C             281\n",
      "MP          C             100\n",
      "S           V             365\n",
      "SD          L             130\n",
      "V           C             89\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "class Bold:\n",
    "    START = '\\033[1m'\n",
    "    END = '\\033[0m'\n",
    "    \n",
    "confusion_matrix = confusion_matrix(y_test, undersampled_prediction_test)\n",
    "print(Bold.START, ' '*5, *['{:>4}'.format(p) for p in parties], Bold.END, sep='')\n",
    "for i in range(len(confusion_matrix)):\n",
    "    print(Bold.START, '{:2s}'.format(parties[i]), Bold.END, confusion_matrix[i])\n",
    "\n",
    "print('\\n', Bold.START, '{0:<10s}  {1:<13s} {2}\\033[0m'.format('Gold', 'Prediction', 'Value'), Bold.END, sep='')   \n",
    "for i in range(len(parties)):\n",
    "    val, j = max( [ (confusion_matrix[i][j], j) for j in range(len(parties)) if i != j])\n",
    "    print('{0:<10s}  {1:<13s} {2}'.format(parties[i], parties[j], val))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a minute to reflect on whether your results make sense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 6: Grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Until now, you have been using the vectorizer and the Naive Bayes classifier with their default hyperparameters. When working with real-world applications, you would want to find settings for the hyperparameters that maximize the performance for the task at hand.\n",
    "\n",
    "Manually tweaking the hyperparameters of the various components of a vectorizer–classifier pipeline can be cumbersome. However, scikit-learn makes it possible to run an exhaustive search for the best hyperparameters over a grid of possible values. This method is known as **grid search**.\n",
    "\n",
    "The hyperparameters of a pipeline should never be tuned on the final test set. Instead, one should either use a separate validation set, or run cross-validation over different folds. Here we will use cross-validation.\n",
    "\n",
    "Implement a grid search with 5-fold cross-validation to find the optimal parameters in a grid defined by the following choices for the hyperparameters:\n",
    "\n",
    "* In the vectorizer, try a set-of-words (binary) model in addition to the default bag-of-words model (two possible parameter values).\n",
    "* Also in the vectorizer, try extracting bigrams in addition to unigrams (two possible parameter values).\n",
    "* In the Naive Bayes classifier, try using additive smoothing with $\\alpha \\in \\{1, 0{.}1\\}$ (two possible parameter values).\n",
    "\n",
    "Use the class [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) from the scikit-learn library. Print the results of your best model, along with the parameter values that yielded these results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'count_vect__binary': True, 'count_vect__ngram_range': (1, 1), 'nbClassifier__alpha': 0.1}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {\n",
    "    'count_vect__binary': [True, False],\n",
    "    'count_vect__ngram_range': [(1, 1), (1, 2)],\n",
    "    'nbClassifier__alpha': (1.0, 0.1),\n",
    "}\n",
    "grid_search = GridSearchCV(pipe, parameters, cv=5)\n",
    "grid_search.fit(x_train, y_train)\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           C       0.43      0.26      0.32       671\n",
      "          KD       0.50      0.21      0.30       821\n",
      "           L       0.37      0.21      0.26       560\n",
      "           M       0.43      0.60      0.50      1644\n",
      "          MP       0.33      0.46      0.39       809\n",
      "           S       0.58      0.68      0.63      2773\n",
      "          SD       0.51      0.39      0.44      1060\n",
      "           V       0.51      0.39      0.44       950\n",
      "\n",
      "    accuracy                           0.48      9288\n",
      "   macro avg       0.46      0.40      0.41      9288\n",
      "weighted avg       0.49      0.48      0.47      9288\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_and_print(True, (1,1), alpha=0.1)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 7: Try to improve your results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn makes it easy to test different vectorizer–classifier pipelines – among other things, it includes different types of logistic regression classifiers, support vector machines, and decision trees. Browse the library to see which methods are supported.\n",
    "\n",
    "Build a pipeline that you find interesting, and use grid search to find optimal settings for the hyperparameters. Print the results of your best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the ComplementNB classifier. It said to be suited for imbalanced data sets, which is the case for the dataset used in this lab\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import ComplementNB\n",
    "\n",
    "pipe = Pipeline([('count_vect', CountVectorizer(tokenizer=preprocess)),\n",
    "                ('nbClassifier', ComplementNB())])\n",
    "pipe.fit(x_train, y_train)\n",
    "print('Using the ComplementNB classifier. It said to be suited for imbalanced data sets, ' + \n",
    "      'which is the case for the dataset used in this lab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'count_vect__binary': False, 'count_vect__ngram_range': (1, 2), 'nbClassifier__alpha': 0.2}\n"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "    'count_vect__binary': [True, False],\n",
    "    'count_vect__ngram_range': [(1, 1), (1, 2), (2, 2)],\n",
    "    'nbClassifier__alpha': (1.0, 0.2, 0.1),\n",
    "}\n",
    "grid_search = GridSearchCV(pipe, parameters, cv=5)\n",
    "grid_search.fit(x_train, y_train)\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           C       0.52      0.24      0.33       671\n",
      "          KD       0.56      0.22      0.31       821\n",
      "           L       0.47      0.18      0.26       560\n",
      "           M       0.43      0.59      0.50      1644\n",
      "          MP       0.35      0.32      0.33       809\n",
      "           S       0.53      0.80      0.64      2773\n",
      "          SD       0.56      0.35      0.43      1060\n",
      "           V       0.54      0.33      0.41       950\n",
      "\n",
      "    accuracy                           0.49      9288\n",
      "   macro avg       0.50      0.38      0.40      9288\n",
      "weighted avg       0.50      0.49      0.47      9288\n",
      "\n",
      "Scores seems to be slightly better than the original model. Not a big difference though.\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([('count_vect',\n",
    "                  CountVectorizer(\n",
    "                      binary=False, \n",
    "                      ngram_range=(1,2),\n",
    "                      tokenizer=preprocess)\n",
    "                 ),\n",
    "                ('nbClassifier',ComplementNB(alpha=0.2))])\n",
    "pipe.fit(x_train, y_train)\n",
    "prediction_test = pipe.predict(x_test)\n",
    "print(classification_report(y_test, prediction_test, target_names=parties))\n",
    "\n",
    "print('Scores seems to be slightly better than the original model. Not a big difference though.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflection questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following reflection questions are questions that you could be asked in the oral exam. Try to answer each of them in the form of a short text and enter it in the cell below. You will get feedback on your answers from your lab assistant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RQ 2.1:** Summarise the results of your experiments for Problem&nbsp;2. Are your results ‘good’ or ‘bad’? How do you determine that?\n",
    "\n",
    ">The result from task 2 is an accuracy on the test data of about 44% which is better than both the dummy classifier and the most frequent class baseline. This implies that the classifier is better than just guessing, which makes it a useful classifier, however the accuracy is not that impressive since the classifier is still wrong more than half of the time. \n",
    "\n",
    "\n",
    "**RQ 2.2:** Summarise the results of your experiments for Problem&nbsp;4. Would you think that your results are typical even for other classification tasks? How would *oversampling* have looked like for this task? When would you use undersampling, when oversampling?\n",
    "\n",
    ">The result from task 4 is a classifier which performs much better on the training dataset, at 95% (compared to the previous 80%) accuracy however the accuracy on the test set has gone down to 38%. This is likely due to the large reduction in training data which reduces the models ability to generalize, and is typical for classification tasks. If we instead used oversampling it could lead to problems with overfitting since there would be a large amount of duplicates from the less frequent classes, such as L. Undersampling improves the distribution by removing information, and if there is a risk of removing invaluable information for the model it should not be used. Oversampling duplicates information and if there is a large risk of overfitting it should not be used. Both of these techniques can also be combined to increase samples of an underrepresented class and decrease the amount of samples from an overrepresented class.\n",
    "\n",
    "**RQ 2.3:** Which model performed best in your experiments for Problem&nbsp;6? Why is it important to do a hyperparameter search before drawing conclusions about the performance of a model? Why is it often not done, anyway? Why should you never tune hyperparameters on the test set?\n",
    "\n",
    "> The model with CountVectorizer_Binary set to True, using only unigrams (ngram_range=(1,1)), and setting the alpha (additive smoothing) value of the NaiveBayes classifier to 0.1 yield best result according to the tests in problem 6. Accuracy went from 44% to 48% after this tuning.\n",
    "\n",
    "> Depending on the model and dataset, different hyperparameters yields different results. Doing a hyperparamenter search to attempt to optimize the hyperparameters is necessary to know the true potential of the model, thus giving it a fair chance. Although this is rarely done, mainly for the following reasons: \n",
    "> 1. It involves generating a lof tests and variations, which can be cumbersome and take a long time\n",
    "> 2. It doesn't always make a big difference and might simply only work well specifically for the training set, so it could be considered a waste of time\n",
    "\n",
    "\n",
    "> Tuning the hyperparameters on the test set means you optimize the performance for that specific dataset. This will improve the results on that particular test, but it can no longer represent the general case anymore. To represent the general case, there is a need for a completely standalone dataset, thus training and tuning hyperparameters on the test set should be avoided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*TODO: Enter your answers here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Congratulations on finishing L2! 👍**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
